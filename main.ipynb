{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Difference Between the latency and ThroughPut\n",
    "    Latency refers to the amount of times taken to the system to respond to the request .   its generally measured in the millisecond and microsecond .\n",
    "\n",
    "    Latency  despendence on the various factor :-\n",
    "\n",
    "    1. network \n",
    "    2. network congestion \n",
    "    3. inefficient algorithm\n",
    "    4. load on resources \n",
    "\n",
    "\n",
    "    throughput refers to the number of the request a system can handle at the same time . it is generally measured in request per second , transactions per second or bits per second .\n",
    "\n",
    "\n",
    "    throughput depend on the various factor :-\n",
    "\n",
    "    1. bandwidth available \n",
    "    2. cpu capacity \n",
    "    3. memory capacity \n",
    "\n",
    "\n",
    "  #### tradeoff between latency and throughput \n",
    "\n",
    "    1. one way to increase the troughput is increase the number of the server to the system . but it will increase the latency . because request should be route to the different server . and replicate the data to the server.\n",
    "\n",
    "\n",
    "    2. other way to increase the throughput is to optimized the server software to handle more request at the same time . but it can also increas the latency , as the server may need to use the more resources to keep up with the increased demand .\n",
    "\n",
    "\n",
    "\n",
    "    hence there is the tradeoff between the latency and throughput . we have choose the right balance between the low latency and high throughput ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
