
Latency refers to the amount of times taken to the system to respond to the request .   its generally measured in the millisecond and microsecond .



Latency  despendence on the various factor :-

1. network 
2. network congestion 
3. inefficient algorithm
4. load on resources 


throughput refers to the number of the request a system can handle at the same time . it is generally measured in request per second , transactions per second or bits per second .


throughput depend on the various factor :-

1. bandwidth available 
2. cpu capacity 
3. memory capacity 


tradeoff between latency and throughput 

1. one way to increase the troughput is increase the number of the server to the system . but it will increase the latency . because request should be route to the different server . and replicate the data to the server.


2. other way to increase the throughput is to optimized the server software to handle more request at the same time . but it can also increas the latency , as the server may need to use the more resources to keep up with the increased demand .



hence there is the tradeoff between the latency and throughput . we have choose the right balance between the low latency and high throughput .


